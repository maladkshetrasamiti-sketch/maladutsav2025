# copilot-instructions.py
"""
Run / Use:
  - Option A (manual): Open this file, copy the big INSTRUCTIONS string and paste into GitHub Copilot chat or GPT-5 prompt window.
  - Option B (auto): Run this script to create TASK.md and per-file prompt files in ./prompts/ for convenience:
        python copilot-instructions.py
"""

from __future__ import annotations
import os
from textwrap import dedent

INSTRUCTIONS = dedent(r"""
==========================
MASTER TASK: NL → KDB Platform
==========================

Goal:
Build a production-ready Natural-Language → KDB query platform. The system includes:
- Orchestrator (FastAPI) that manages user sessions, embeddings, VectorDB retrieval, enrichment, and routing.
- LLM integration (Chat completions / function-calling style) to produce structured tool calls (JSON).
- VectorDB ingestion (Qdrant local) for schema, column descriptions, templates, examples, and user memory.
- MCP-style dynamic template executor (stateless), implemented as a Python module that can be run either as a standalone process or behind FastAPI.
- Q-Template library (YAML .qtpl files) for safe query shapes plus one generic template.
- Guardrails & JSON-schema validator for tool calls.
- Security: auth (JWT), RBAC, rate-limiting.
- Redis for session memory, optional cache.
- Tests (pytest) and Dockerfiles for local dev.

Tech stack & libraries (use these explicitly):
- Python 3.11
- FastAPI, uvicorn
- pydantic
- qdrant-client[qdrant-local]
- openai (for embeddings + chat) OR a pluggable LLM interface
- pykx (or qpython) for KDB connectivity
- redis (aioredis)
- pytest
- PyYAML
- black/ruff formatting
- typing + type hints for all public functions

Important constraints (enforce these in code):
- All LLM outputs must be validated by Guardrails JSON schema.
- MCP executor must be stateless: session state lives only in the Orchestrator (Redis/DB).
- Templates must be stored as YAML with `template`, `parameters`, `constraints`, `examples`.
- No raw LLM-generated q should be executed without passing through template/AST validation & policy engine.
- Provide unit tests for validator and template loader.
- Use Qdrant local mode for dev.

Deliverable structure:
The assistant (Copilot/GPT-5) must produce the following files and folders in project root.

Project folder tree (create exactly):

nl2kdb/
├── README.md
├── pyproject.toml
├── docker-compose.yml
├── .env.example
├── TASK.md                # (auto-generated by this prompt)
├── prompts/               # (optional prompt snippets written by this script)
│   ├── orchestrator__main.md
│   ├── mcp_server__server.md
│   ├── ingestion__schema_extract.md
│   └── templates__samples.md
├── orchestrator/
│   ├── main.py
│   ├── config.py
│   ├── auth.py
│   ├── vector_search.py
│   ├── prompt_builder.py
│   ├── session_store.py
│   ├── llm_client.py
│   └── schemas.py
├── mcp_server/
│   ├── server.py
│   ├── template_loader.py
│   ├── validator.py
│   ├── policy_engine.py
│   └── q_runner.py
├── ingestion/
│   ├── schema_extract.py
│   ├── embed_and_ingest.py
│   └── chunker.py
├── templates/
│   ├── last_trades.qtpl.yml
│   ├── trades_in_range.qtpl.yml
│   ├── vwap.qtpl.yml
│   ├── ohlc.qtpl.yml
│   └── generic_select.qtpl.yml
├── tests/
│   ├── test_template_loader.py
│   ├── test_validator.py
│   └── test_orchestrator_flow.py
└── infra/
    ├── Dockerfile
    └── k8s-deploy.yaml

--------------------------
FILE-BY-FILE PROMPTS (paste into each file when generating)
--------------------------

1) TASK.md (master)
-------------------
Write a TASK.md at project root with the MASTER TASK description (this whole INSTRUCTIONS content). This file serves as the single specification for Copilot.

2) orchestrator/main.py
-----------------------
Prompt:
"""
Create orchestrator/main.py.

- Implement FastAPI app with one POST endpoint: /query
- Accept a JSON payload: { "user_id": str, "query": str, "session_id": Optional[str] }
- Steps inside endpoint (async):
  1. Authenticate request (auth.py)
  2. Use session_store to retrieve user session memory (Redis)
  3. Call llm_client.embed_query(query) -> embedding vector
  4. Use vector_search.search(embedding, top_k=8) to fetch schema & template docs from Qdrant
  5. Build enriched prompt via prompt_builder.build_prompt(query, session, chunks)
  6. Call llm_client.generate_tool_call(enriched_prompt) -> should return JSON {tool, args}
  7. Validate JSON with guardrails (schemas.GuardrailModel)
  8. If valid, forward to MCP via aiohttp or local function call: mcp_server.run_template(tool, args, user_id)
  9. Normalize result and return JSON to client
  10. Log & save conversation step to session_store and ingest feedback to VectorDB if applicable

- Use Pydantic models for request/response shapes.
- Include background tasks to store logs and update vector DB asynchronously.
- Add typed exceptions and error handling for validation or execution failure.
"""

3) orchestrator/config.py
-------------------------
Prompt:
"""
Create orchestrator/config.py

- Use pydantic BaseSettings for config values:
  - OPENAI_API_KEY
  - QDRANT_URL or local mode flag
  - REDIS_URL
  - KDB connection info (host, port, user)
  - MAX_ROWS, DEFAULT_LIMITS
  - JWT secret, RBAC roles
- Provide type hints and .env loading support.
"""

4) orchestrator/auth.py
-----------------------
Prompt:
"""
Create orchestrator/auth.py

- Implement JWT-based auth dependency for FastAPI (pydantic token models).
- Implement role-checking function: require_role(user, roles: List[str]).
- Provide a stub get_current_user(token) that decodes JWT and returns Pydantic user model.
- Use fastapi.Security dependencies and raise HTTPException(401/403) where needed.
"""

5) orchestrator/session_store.py
--------------------------------
Prompt:
"""
Create orchestrator/session_store.py

- Implement an async session store using aioredis.
- Functions:
  - get_session(user_id, session_id) -> dict
  - save_session(user_id, session_id, session_data)
  - append_conversation(user_id, entry)
  - get_recent_history(user_id, n=10)
- Use JSON serialization, TTL management, and typed Pydantic models.
"""

6) orchestrator/vector_search.py
--------------------------------
Prompt:
"""
Create orchestrator/vector_search.py

- Implement Qdrant client wrapper for local development (qdrant-client[qdrant-local]).
- Functions:
  - init_qdrant_client(path_or_url)
  - upsert_chunks(chunks: List[dict])
  - semantic_search(embedding: List[float], top_k: int, filter: Optional[dict]=None) -> List[chunks]
- Ensure metadata payload, filtering, and distance metric configuration.
- Provide simple helper to convert chunk objects to qdrant payloads.
"""

7) orchestrator/prompt_builder.py
---------------------------------
Prompt:
"""
Create orchestrator/prompt_builder.py

- Build enriched prompt for the LLM using:
  - recent session history
  - the user query
  - the top-k retrieved VectorDB chunks
  - examples from templates
- The function build_prompt(query, session, chunks) should return a string to be passed to the LLM.
- Keep the prompt length under a configurable token cap; trim low-relevance chunks if needed.
"""

8) orchestrator/llm_client.py
-----------------------------
Prompt:
"""
Create orchestrator/llm_client.py

- Wrap the LLM provider (OpenAI or a pluggable provider).
- Functions:
  - embed_text(text) -> vector
  - generate_tool_call(prompt, tools) -> JSON (tool_name, args)
  - summarize_result(json_result) -> human-friendly text
- Use strong retry logic and clear exceptions.
- Respect rate limits and provide async methods.
"""

9) orchestrator/schemas.py
--------------------------
Prompt:
"""
Create orchestrator/schemas.py

- Pydantic models for:
  - QueryRequest (user_id, session_id, query)
  - ToolCall (tool: str, args: dict)
  - TemplateParam types
  - Guardrail error model
- Export a JSON schema for tool-call validation (used by guardrails).
"""

10) mcp_server/server.py
------------------------
Prompt:
"""
Create mcp_server/server.py

- Implement a dynamic template-runner service exposing one function run_template(template_name: str, params: dict, user_id: Optional[str]).
- Behavior:
  1. Load template definition from template_loader
  2. Validate params via validator.validate(template, params)
  3. Render q string via template.render_safe(params)
  4. Validate AST via policy_engine.ast_check(q_string)
  5. If approved, send to q_runner.execute(q_string) and return result
- The module should be callable locally (import) and also expose a minimal CLI for debugging:
    python -m mcp_server.server run_template last_trades '{"sym":"AAPL","n":5}'
- Use async functions and return JSON serializable results.
"""

11) mcp_server/template_loader.py
--------------------------------
Prompt:
"""
Create mcp_server/template_loader.py

- Load all YAML templates from templates/ folder.
- Provide get_template(name) -> Template object
- Template object fields: name, description, parameters (dict), constraints, q_body
- Validate template syntax at load time and raise descriptive errors.
- Implement reload_templates() for dynamic loading in dev mode.
"""

12) mcp_server/validator.py
---------------------------
Prompt:
"""
Create mcp_server/validator.py

- Validate runtime parameters against template parameter definitions:
  - type checking (symbol, int, float, timestamp)
  - min/max constraints
  - allowed values / enum checks
  - sanitize symbol strings (no backticks or semicolons)
- Return detailed error messages for failing validations.
"""

13) mcp_server/policy_engine.py
-------------------------------
Prompt:
"""
Create mcp_server/policy_engine.py

- Implement policy checks: max_rows, max_time_range, allowed_tables, forbidden_columns
- Implement an AST check function (very simple parser or regex-based safety checks) that forbids:
  - update/insert/delete
  - system calls
  - backticks injection
  - semicolons that separate statements
- Optionally implement a cost_estimate function that runs a dry-run against a shadow KDB instance to estimate row count.
"""

14) mcp_server/q_runner.py
--------------------------
Prompt:
"""
Create mcp_server/q_runner.py

- Implement a thin wrapper around pykx.QConnection or qpython.
- Provide execute(q_string, timeout_ms=200) -> dict/json
- Use async wrapper if pykx supports it (or run in threadpool).
- If KDB is not available, return a simulated result for dev mode.
- Ensure results are converted to JSON-safe types.
"""

15) ingestion/schema_extract.py
--------------------------------
Prompt:
"""
Create ingestion/schema_extract.py

- Connect to KDB (pykx) and extract:
  - list of tables
  - for each table: meta (column names + types), sample rows (n=5), cardinality estimations
- Output schema.json and individual table JSONs in ingestion/out/
- Include CLI mode: if run locally, dump schema to file.
"""

16) ingestion/chunker.py
------------------------
Prompt:
"""
Create ingestion/chunker.py

- Convert schema artifacts into semantic chunks:
  - chunks for table schema
  - chunks for column description
  - chunks for example queries (derived from templates)
  - chunks for business definitions (e.g., VWAP)
- Each chunk = {id, text, metadata}
- Provide chunk size and chunk overlap config
"""

17) ingestion/embed_and_ingest.py
---------------------------------
Prompt:
"""
Create ingestion/embed_and_ingest.py

- Read ingestion/out/schema.json
- For each chunk, create an embedding using llm_client.embed_text
- Upsert to Qdrant using orchestrator.vector_search.upsert_chunks
- Support batch mode and progress reporting
"""

18) templates/*.qtpl.yml
------------------------
Prompt:
"""
Create template YAML examples in templates/:
- last_trades.qtpl.yml
- trades_in_range.qtpl.yml
- vwap.qtpl.yml
- ohlc.qtpl.yml
- generic_select.qtpl.yml

Each template must have:
- name
- description
- parameters: name, type, required, min/max, description
- template: q string with $var placeholders (no concatenation)
- examples: sample NL and args
- constraints: max_rows, allowed_tables
"""

19) tests/test_template_loader.py
---------------------------------
Prompt:
"""
Create pytest unit tests for template loader.
- Test: load_templates loads all YAML templates
- Test: get_template returns Template object with expected fields
- Test: malformed template raises descriptive error
"""

20) tests/test_validator.py
---------------------------
Prompt:
"""
Create pytest tests for validator.
- Test: valid params pass
- Test: invalid type fails with message
- Test: symbol injection is rejected
"""

21) infra/Dockerfile & docker-compose.yml
-----------------------------------------
Prompt:
"""
Create Dockerfile for python app and docker-compose.yml that orchestrates:
- orchestrator (FastAPI)
- qdrant (local image or qdrant-local)
- redis
- optional kdb mock container (simulate queries)
- Postgres for audit (optional)
"""

22) README.md
-------------
Prompt:
"""
Create README.md.
- Overview architecture
- How to run locally: pip install -r requirements, run qdrant-client local, run redis, run orchestrator, run ingestion to populate vector DB, run mcp_server in dev mode.
- Example curl to /query
- How to run tests
"""

--------------------------
USAGE NOTES for Copilot / GPT-5
--------------------------
1. Use the MASTER TASK first to scaffold repo skeleton (folders + files).
2. Generate each module one by one using the per-file prompt blocks above.
3. After each file generation, run tests and fix failing areas interactively:
   - First implement template_loader + validator + tests.
   - Implement ingestion and vector db ingestion with sample chunks.
   - Implement orchestrator main with mock llm_client that returns deterministic tool calls.
   - Implement MCP server runner and connect to pykx mock.
   - Integrate end-to-end.

4. Use small iterative commits. Add type hints and tests for everything.

5. When Copilot suggests code, enforce:
   - no inline string substitution for q (use safe templating only)
   - always sanitize inputs
   - guardrails run on every LLM output

--------------------------
EXAMPLE: minimal last_trades.qtpl.yml
--------------------------
name: last_trades
description: "Return last N trades for a given symbol, sorted by time desc."
parameters:
  sym:
    type: symbol
    required: true
    description: "Ticker symbol (uppercase)"
  n:
    type: int
    required: true
    min: 1
    max: 5000
template: |
  select from trade
    where sym=`$sym
    by time desc
    limit $n
examples:
  - nl: "show me last 10 trades for AAPL"
    args: { sym: "AAPL", n: 10 }
constraints:
  allowed_tables: ["trade"]
  max_rows: 5000
  max_execution_ms: 500

--------------------------
TEST CASES (high-level)
--------------------------
- Valid NL query "show me last 5 trades for AAPL" returns 5 rows for AAPL.
- Malicious NL "run system ls" must be rejected by guardrails before touching MCP.
- Oversize request "last 1000000 trades" must be limited by policy_engine before executing.
- Ambiguous NL "show me trades" should prompt clarifying question using session history.

--------------------------
DELIVERABLE: What to return to me
--------------------------
1. Create the repo skeleton exactly as described.
2. Implement core modules with working minimal logic (template loader, validator, MCP run_template, simple orchestrator /query endpoint that uses a mock LLM).
3. Include unit tests for template loader and validator.
4. Provide instruction in README for full integration steps.

--------------------------
END OF INSTRUCTIONS
==========================
""")

# Optional: create prompts/ directory + TASK.md
if __name__ == "__main__":
    os.makedirs("prompts", exist_ok=True)
    with open("TASK.md", "w", encoding="utf8") as f:
        f.write(INSTRUCTIONS)
    # also split and write per-file prompts to prompts/
    sections = INSTRUCTIONS.split("2) orchestrator/main.py")
    # naive: write whole instruction into prompts/master.md too
    with open("prompts/master.md", "w", encoding="utf8") as f:
        f.write(INSTRUCTIONS)
    print("Wrote TASK.md and prompts/master.md. Open TASK.md and paste into Copilot/GPT-5 to scaffold the project.")
